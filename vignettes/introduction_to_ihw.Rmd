---
title: "Introduction to IHW"
author: "Nikos Ignatiadis"
date: "`r doc_date()`"
package: "`r pkg_ver('IHW')`"
output: BiocStyle::html_document
bibliography: bibliography.bib
vignette: >
  %\VignetteIndexEntry{"Introduction to IHW"}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
---

# Introduction

You will probably be familiar with multiple testing procedures that take a set of p-values and then calculate adjusted p-values. Given a significance level $\alpha$, one can then declare the rejected hypotheses. In R this is most commonly done with the `p.adjust` function in the `stats` package.

Similarly, IHW (Independent Hypothesis Weighting) is also a multiple testing procedure [@ignatiadis2015data], but beyond the p-values, it also requires a covariate for each test. The covariate should be informative of the power or prior probability of each individual test, but is chosen such that the p-values for those hypotheses that are truly null do not depend on the covariate. Therefore the input of IHW is the following:

* a vector of p-values,
* a matching vector of covariates, 
* the significance level $\alpha \in (0,1)$ at which the False Discovery Rate should be controlled.

IHW then calculates weights for each p-value and also a vector of adjusted p-values. The weights allow different prioritization of the individual hypotheses, based on their covariate. A hypothesis with weight > 1 gets prioritized in the testing procedure and the higher the weight the higher the prioritization. On the other hand, a hypothesis with weight equal to 0 cannot be rejected and essentially is filtered out of the procedure.

To be more precise, assume we have $m$ different hypothesis tests. Then the hypothesis weights are non-negative numbers $w_i \geq 0$ such that $\sum_{i=1}^m w_i = m$. We then define the weighted p-values as $P^\text{weighted}_i = \frac{P_i}{w_i}$ and then plug these weighted p-values (instead of the p-values) into the procedure of Benjamini and Hochberg. 

Thus, the covariates allows us to learn weights in a data-driven way and therefore we can gain a lot of power compared to an unweighted method (an unweighted method is a weighted method where all tests are assigned weight 1).

In this vignette, we will show how to use the IHW package in differential gene expression RNA-Seq analysis and then also mention some other examples where our method is applicable.

# IHW and DESeq2

We analyze the airway RNA-Seq dataset using DESeq2 [@love2014moderated].

```{r, message=FALSE, warning=FALSE}
library("methods")
library("airway")
library("DESeq2")
data("airway")
dds <- DESeqDataSet(se = airway, design = ~ cell + dex)
dds <- DESeq(dds)
res <- results(dds)
```

The output is a `DESeqResults` object, which includes the following columns for each gene:

```{r}
colnames(res)
```

In particular, we have p-values and the baseMean of (normalized) counts for each gene. As argued in the DESeq2 paper, these two statistics are approximately independent under the null hypothesis. Thus we have all the ingredient necessary for a IHW analysis (p-values and covariates), which we will apply at a significance level 0.1.

First load IHW:
```{r, message=FALSE, warning=FALSE}
library("IHW")
ihw_res <- ihw(res$pvalue, res$baseMean, alpha = 0.1)
```

This returns an object of the class `ihwResult`. We can get e.g. the total number of rejections.

```{r}
rejections(ihw_res)
```

And we can also extract the adjusted p-values:
```{r}
head(adj_pvalues(ihw_res))
sum(adj_pvalues(ihw_res) <= 0.1, na.rm = TRUE) == rejections(ihw_res)
```

We can compare this to the result of applying the method of Benjamini and Hochberg to the p-values only:

```{r}
padj_bh <- p.adjust(res$pvalue, method = "BH")
sum(padj_bh <= 0.1, na.rm = TRUE)
```

We thus get a lot more rejections! How did we get this power? Essentially it was possible by assigning appropriate weights to each hypothesis. We can retrieve the weights as follows:

```{r}
head(weights(ihw_res))
```


Internally, what happened was the following: We split the hypotheses into $n$ different strata based on increasing value of baseMean and we also randomly split them into $k$ folds (here $k=5$). Then, for each combination of fold and stratum, we learned the weights. The discretization into strata facilitates the estimation of the distribution function conditionally on the covariate and the optimization of the weights. The division into random folds helps us to avoid "overfitting" the data, something which can result in loss of control of the False Discovery Rate.

In particular, each hypothesis test gets assigned a weight depending on the combination of its assigned fold and stratum.

We can also see this internal representation of the weights as a ($n$ X $k$) matrix:

```{r}
weights(ihw_res, levels_only=TRUE)
```

Finally, IHW contains a convenience function to visualize the estimated weights:

```{r}
plot(ihw_res)
```

Here we see that the general trend is driven by the covariate (stratum) and not as much by the fold. Also as expected, genes with very low baseMean count get assigned a weight of 0, while genes with high baseMean count get prioritized.

As a further convenience for further work, a ihwResult object can be converted to a data.frame as follows:

```{r}
colnames(as.data.frame(ihw_res))
```

# Regarding the covariate

In which cases is IHW applicable? Whenever we have a covariate which is both informative of power and independent of the p-values under the null hypothesis.

Below we summarize some examples where such a covariate is available:

 *  For row-wise $t$-tests we can use the overall (row-wise) variance [@bourgon2010independent]. 
 *  For row-wise rank-based tests (e.g. Wilcoxon) we can use any function that does not depend on the order of arguments [@bourgon2010independent].
 *  In DESeq2, we can use baseMean, as illustrated above [@love2014moderated].
 *  In  eQTL analysis we can use the SNP-gene distance, the DNAse sensitivity, the HiC score, etc. 

# Advanced usage: Working with incomplete p-value lists

So far, we have assumed, that a complete list of p-values is available, i.e. one p-value per hypothesis. However, this information is not always available or practical:

 * This can be related to the software tools used for the calculation of the p-values. For example, as noted in [@ochoa2015beyond], some tools such as HMMER, only return the lowest p-values. In addition, other tools, such as MatrixEQTL [@shabalin2012matrix] by default only return p-values below a pre-specified threshold, for example all p-values below $10^{-5}$. In the case of HMMER, this is done because higher p-values are not reliable, while for MatrixEQTL it reduces storage requirements. 
 * Even if p-values for all hypotheses are available, it might still be infeasible to load all of them into RAM. In addition, it could be possible that the p-value vector only barely fits into RAM, so that the subsequent IHW call will run out of memory or will be very slow.
 
Since rejections take place for low p-values (at the tails of the p-value distribution), we do not lose a lot of information by discarding the high p-values from the analysis, as long as we keep track of how many large p-values have been omitted. Thus, the above situations can be easily handled.

Before proceeding with the walkthrough for handling such cases with IHW, we quickly review how this is handled by `p.adjust`. We first simulate some data, where the power under the alternative depends on a covariate. p-values are calculated by a simple one-sided z-test.

```{r}
set.seed(1)
X   <- runif(100000, min=0, max=2.5) #covariate
H   <- rbinom(100000,1,0.1)            #hypothesis true or false
Z   <- rnorm(100000, H*X)              #Z-score
pvalue <- 1-pnorm(Z)                  #pvalue
sim <- data.frame(X=X, H=H, Z=Z, pvalue=pvalue)
```

We can run Benjamini-Hochberg on these p-values:

```{r}
sum(p.adjust(sim$pvalue, method="BH") <= 0.1)
```

Now assume we only have access to the p-values $\leq 0.1$:

```{r}
filter_threshold <- 0.1
pvalue_filt <- pvalue[pvalue <= filter_threshold]
```

Then we can still use `p.adjust`, as long as we inform it of how many hypotheses were really tested (not just the ones with p-value $\leq 0.1$). We specify this by setting the `n` keyword argument.

```{r}
sum(p.adjust(pvalue_filt, method="BH", n=length(pvalue)) <= 0.1)  
```

We see that we get exactly the same number of rejections, as when we used the whole p-value vector as input. Now, the same principle applies to IHW, but is slighly more complicated. In particular, we need to provide information about how many hypotheses were conducted at each given value of the covariate. This means that there are two modifications to the standard IHW workflow: 

 * If a numeric covariate is provided, IHW internally discretizes it and 
in this way bins the hypotheses into groups (strata). For the advanced functionality, this discretization has to be done manually by the user. In other words, the covariate provided by the user will have to be a factor. For this, the convenience function `groups_by_filter` is provided, which returns a
factor that stratifies a numeric covariate into a given number of
groups with approximately the same number of hypotheses in each of the
groups. 
 * For the algorithm to work correctly, it is necessary to know the total
number of hypotheses in each of the bins. However, if filtered p-values
are used, IHW obviously cannot infer the number of hypotheses per bin
automatically.Therefore, the user has to specify the number of hypotheses per bin
manually via the `m_groups` option. (When there is only 1 bin, IHW reduces to BH and `m_groups` would be
equivalent to the `n` keyword of `p.adjust`.)

For example, when the whole grouping factor is available (e.g. when it was generated by using `groups_by_filter` on the full vector of covariates), then one can apply the  `table` function  on it 
to calculate the number of hypotheses per bin. This is then
used as an input for the `m_groups` argument. More elaborate strategies might be needed in more complicated case, 
e.g. when the full vector of covariates can also not fit into RAM.

```{r}
nbins <- 20
sim$group <- groups_by_filter(sim$X, nbins)
m_groups <- table(sim$group)
```

Now we can subset our data frame to only keep low p-values and then apply IHW with the manually specified `m_groups`.

```{r}
sim_filtered <- subset(sim, sim$pvalue <= filter_threshold) 
ihw_filt <- ihw(sim_filtered$pvalue, sim_filtered$group, .1, m_groups = m_groups)
rejections(ihw_filt)
```

# References
